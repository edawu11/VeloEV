{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607b1b58",
   "metadata": {},
   "source": [
    "# 1. Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e705e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import pickle\n",
    "import veloev as vev\n",
    "\n",
    "# You should modify the data path to your local data folder.\n",
    "os.chdir(\"/mnt/e/project/Benchmark_velocity/veloev/demo/demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271c3b4",
   "metadata": {},
   "source": [
    "To begin, you should define the `benchmark_info` configuration dictionary. This dictionary controls the inputs and parameters for the evaluation pipeline. The required keys are:\n",
    "\n",
    "- methods (list): A list of method names. These names must correspond to the velocity layer keys in adata.layers and the method identifiers in the filenames.\n",
    "\n",
    "- methods_map (dict): A dictionary for visualization purposes. It maps the internal method names (keys) to their display labels (values).\n",
    "\n",
    "- datasets_name (list): A list of dataset names. Each name must match a corresponding folder name in your data directory.\n",
    "\n",
    "- tasks (list): A list of tasks to execute. The package supports eight tasks: directional, temporal, directional_temporal, negative_control, seq_depth_directional, seq_depth_temporal, seq_depth_directional_temporal, and simulation.\n",
    "\n",
    "- k_folds (list): A list defining the number of cross-validation folds (k-folds) to run for each respective dataset.\n",
    "\n",
    "- cluster_key (list): The column name in adata.obs containing cluster annotations. Required for directional tasks; set to None otherwise.\n",
    "\n",
    "- time_key (list): The column name in adata.obs containing latent time or pseudotime. Required for temporal tasks; set to None otherwise.\n",
    "\n",
    "- cell_type_transitions (list): Defines the ground-truth transitions between cell types for directional tasks.\n",
    "\n",
    "- time_transitions (list): Defines the ground-truth time transitions for temporal tasks.\n",
    "\n",
    "If you are using our toy example (available via this [link](https://drive.google.com/drive/folders/1GWvnG897EhheAcX-oKjMq_z5d9Mrd4Ln?usp=sharing)), you can use the configuration below directly. For custom datasets, please adapt the dictionary to follow this template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd748145",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_info = {\n",
    "    'methods': ['scvelo_stc','sdevelo','unitvelo_uni','velocyto'],\n",
    "    'methods_map': {'scvelo_stc': 'scVelo (stc)',\n",
    "                    'sdevelo': 'SDEvelo',\n",
    "                    'unitvelo_uni': 'UniTVelo (uni)',\n",
    "                    'velocyto': 'Velocyto'},\n",
    "    'datasets_name': ['01_bone_marrow', \n",
    "                    '07_fucci_u2os',\n",
    "                    '11_pbmc68k'],\n",
    "    'tasks': ['directional',\n",
    "                'temporal',\n",
    "                'negative_control'],\n",
    "    'k_fold': [3, 3, 5],\n",
    "    'cluster_key': ['clusters', None,'celltype'],\n",
    "    'time_key': [None, 'dtime',None],\n",
    "    'cell_type_transitions':[[(\"HSC_1\", \"Ery_1\"), (\"HSC_1\", \"HSC_2\"), (\"Ery_1\", \"Ery_2\")],\n",
    "                                None,\n",
    "                                None],\n",
    "    'time_transitions': [None,\n",
    "                         [(0, 1), (1, 2), (2, 3), (3, 4)],\n",
    "                         None]}\n",
    "\n",
    "# If use full data, please set k_fold to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb0c74",
   "metadata": {},
   "source": [
    "Then, we provide a function to validate the contents of `benchmark_info` and summarize the benchmark configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad1ff7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸ”¹ STEP 1: VALIDATION CHECK\n",
      "==================================================\n",
      "âœ… Optional Check: 'methods_map' correctly covers all methods.\n",
      "âœ… Validation Successful: Configuration is valid.\n",
      "ðŸ’¾ File Saved: benchmark_info.pkl\n",
      "\n",
      "==================================================\n",
      "ðŸ”¹ STEP 2: SUMMARY REPORT\n",
      "==================================================\n",
      "â€¢ Total Methods:  4\n",
      "  â””â”€ scvelo_stc (scVelo (stc)), sdevelo (SDEvelo), unitvelo_uni (UniTVelo (uni)), velocyto (Velocyto)\n",
      "â€¢ Total Datasets: 3\n",
      "\n",
      "ðŸ“‹ Dataset Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Task</th>\n",
       "      <th>Dataset Names</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>directional</td>\n",
       "      <td>01_bone_marrow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temporal</td>\n",
       "      <td>07_fucci_u2os</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative_control</td>\n",
       "      <td>11_pbmc68k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset Task   Dataset Names  Count\n",
       "0       directional  01_bone_marrow      1\n",
       "1          temporal   07_fucci_u2os      1\n",
       "2  negative_control      11_pbmc68k      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vev.pp.check_save_summarize_info(benchmark_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c12cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"benchmark_info.pkl\", \"rb\") as f:\n",
    "    benchmark_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611b9ea",
   "metadata": {},
   "source": [
    "You are now ready to begin post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b4979ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting post-processing for 3 datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 11_pbmc68k: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:17<00:00, 65.88s/dataset]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Post-processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vev.pp.run_postprocessing(benchmark_info, base_dir='./', n_jobs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a57481",
   "metadata": {},
   "source": [
    "In the next tutorial, we will cover the evaluation process!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
